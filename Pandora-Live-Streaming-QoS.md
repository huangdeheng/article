# 使用 Pandora 平台玩转直播实时质量监控

## 阅读对象

直播平台开发运维人员

## 背景

去年(2016年)被称为直播元年，各类移动直播平台如雨后春笋冒出，不断满足人们对强交互、高实时性的新媒体载体的要求。直播过程中所涉及的环节众多，诸如推流、网络传输、节点调度、流处理和播放等，要全面地建立起一套能够对各个环节性能进行监控的系统绝非易事。目前七牛直播云已经建立起一套完善的内部数据监控平台，实现了一个智能调度、按需伸缩、高容错的实时流网络，我们称之为 LiveNet。LiveNet 完美解决了直播场景的三高之痛：技术门槛高、成本高、卡顿延时率高。

然而，在实际的客户对接及服务过程中，各式各样的问题仍然不可避免，如直播卡顿、马赛克、花屏、黑屏、杂音、音画不同步等等。这些问题中，有些是传输链路原因，有些是用户的使用姿势引起，有些是参数配置错误所致，也有些是直播 SDK 本身的问题。很多情况下，如果没有足够的数据线索进行支撑，应对线上用户反馈的这类问题，直播平台开发者经常两眼一抹黑，定位问题基本只能靠猜。通常情况下，在直播客户没有建立自己的直播质量监控系统时，七牛云的专业技术服务团队是客户排障的第一选择。针对绝大部分常见的问题，七牛云技术支持能够快速提供排查建议，如帮助查询某路直播流的实时状态，判断主播推流的稳定性。

但是，由于七牛云直播技术支持并没有直接接触到各个直播客户的终端用户，在问题排查过程中难免存在信息不对称的情况，增大沟通的时间成本。特别是当直播客户线上问题集中爆发时，如果直播平台的开发者没有一个系统的途径能够进行自查，势必使得该直播平台的用户体验陡然下降。那么，建立一个直播质量监控系统需要有哪些投入呢？以下我们为您详细解析。

## 直播质量监控系统

通常来说，如果要建立一套自己的直播质量监控体系，一般要完成以下几个步骤：

1. 在 App 端埋点，收集由直播 SDK 回调的音视频帧率、码率等与直播质量相关的数据，并进行上报；
2. 建立一个收点的网关，如果数据量太大，还需要 Kafka 等队列做数据缓存；
3. 搭建 HDFS 、 Elasticsearch 等存储服务，将接收的 QoS 数据转存到这些存储系统；
4. 搭建一套实时/离线数据流分析服务；
5. 数据可视化展示、告警系统。

实现以上功能，不仅需要有一个资深大数据背景的技术团队和客户端团队的支撑以及漫长的开发周期，系统上线后仍需持续投入精力持续维护迭代，以应对诸如逐步上升的数据量；若是对平台的横向扩展能力没考虑周全，众多开源组件崩盘的风险很可能会让之前的投入白费。

那么，有没有一种不需要自己造轮子的途径，去实现绝大部分质量监控功能？如今，我们给出了肯定的回答！借助于七牛大数据平台 Pandora，以及七牛直播云 SDK 所集成的 QoS 质量上报模块，七牛直播云用户能够快速打造一套属于自己的实时直播质量监控系统，并实现各种维度的自定义分析能力。

### 七牛大数据平台 Pandora

七牛大数据平台 Pandora 是一套面向海量数据，能够让基础技术人员轻松管理大数据传输、计算、存储和分析的大数据 PaaS 平台，提供简单、高效、开放的一站式大数据服务，核心服务及功能包括大数据工作流引擎、时序数据库、日志检索服务、Spark 服务、报表工作室。同时提供了海量离线数据分析等众多大数据分析工具支持，并结合七牛云生态，赋能应用大数据的核心能力，让用户可将资源精力聚焦于业务价值提升而无需担忧复杂的大数据技术和部署运维难题。

### 直播 QoS

直播质量实时上报模块 (QoS) 几乎是每个直播 SDK 的必要组成部分，它对于提升直播 SDK 性能以及直播网络的节点调度策略、链路质量具有重要作用。七牛云直播 SDK 的 QoS 模块作为可选模块，默认处于开启状态，其传输数据是透明的，用户可选择性进行关闭或开启。

## 如何启用七牛直播质量监控服务

- 直播云 SDK 集成
首先，请确保您的直播 App 集成了最新版本的七牛推流/播放 SDK。是的，在移动端，您要做的就是这么简单！
- 创建 Grafana App
![图3.1 Grafana APP 创建](http://op26gaeek.bkt.clouddn.com/newbuildGrafana.png)
- 载入我们为您提供的 Grafana 配置

完成以上步骤后，便已万事俱备，只待直播质量日志的持续上报。

至此，您已经可以：

1. 在 Grafana 中观察到精细到每个流的质量变化曲线；
2. 通过 Pandora 日志服务 LogDB 所提供的强大日志检索功能，快速回溯追踪每个流或某个用户设备的数据。

### Grafana 数据可视化展示

目前，我们为您预先内置了五个直播质量统计场景，分别是推流状态、服务器状态、播放地域统计、播放终端跟踪和地区运营商状态。

* 推流各质量指标曲线，实时查看每个推流的音视频帧率、码率等指标的变化
![图3.2 单个推流的实时质量曲线](http://owlznavag.bkt.clouddn.com/stream-stats-dashboard.png)

* 地区运营商平均推流质量曲线，可快速了解某地区、某运营商的总体推流状况
![图3.3 城市运营商平均音频发送帧率曲线](http://owlznavag.bkt.clouddn.com/audio-fps-region-isp.png)

* 播放终端质量曲线，查看总体播放质量变化，或精细到单设备的各项播放指标监控
![图3.4 播放终端平均质量曲线](http://owlznavag.bkt.clouddn.com/player-stats.png)

* 直播流在某区域运营商的播流质量曲线，让每个流在每个城市、运营商的播放质量都能得到监控
![图3.5 播流地域统计](http://owlznavag.bkt.clouddn.com/stream-play-stats-region-isp-dashboard.png)

* 推流加速节点的平均质量曲线，用于帮助判断是否由于推流节点的负载变化导致直播质量的变化
![图3.6 推流节点平均质量曲线](http://owlznavag.bkt.clouddn.com/server-stats-dashboard.png)
需要指出的是，这些内置场景只是 QoS 数据的一小部分应用，您可以根据需求拓展或增加 Grafana 的 Dashboard，关注您想要的质量维度。

### LogDB 直播质量日志检索

事实上，直播质量日志在被可视化呈现之前，会被先导入到 Pandora LogDB 日志检索服务中。您可登录七牛官方网站，在日志检索模块中进行直播质量日志搜索。并且 LogDB 无缝兼容 Elasticsearch 协议，您也可使用我们为您提供的 Kibana 应用玩转日志检索。通过质量日志搜索，您可以进行各种直播问题的查询，如根据某个设备 id 进行单用户的日志回溯，进行用户级别的直播排障。

![图3.7 LogDB 使用](http://owlznavag.bkt.clouddn.com/logdb-usage.png)

### 直播排障

那么，这些可视化图表及日志搜索该如何派上实际用场呢？下面我们就以一个常见的直播排障场景来说明这些数据在定位问题中能够给到直播厂商的帮助，使直播平台的技术人员能够自助快速排障。

假设某个主播向直播平台反馈直播卡顿，那么，直播平台的技术人员首先获取到该主播的流 id，然后在 Grafana 的`流状态` Dashboard 中，过滤出这个流，发现其推流曲线如下：

![图3.8 直播流质量曲线](http://owlznavag.bkt.clouddn.com/single-stream-stat.png)

从时序图中，可以看到有几个时间点推流的音视频帧率、码率都降为0，存在一定的波动。那么，这个波动是由什么原因引起的呢？是主播的网络不稳定？主播将直播 App 退至后台进行了其他操作？还是推流的节点负载过重？

为了回答上面的猜测，直播技术客服利用日志检索服务进行更进一步的问题追踪，那便是在 LogDB 中搜索推流 id，回溯主播的推流行为。

![图3.9 LogDB 直播问题回溯](http://owlznavag.bkt.clouddn.com/logdb-trace.png)

通过搜索该主播设备上报的直播质量日志，可以发现，在音视频发送帧率降为0的几个时间点，其音视频的编码帧率也为0，并且视频发送缓冲区的丢帧率为0，这说明了并非由于主播网络问题导致发送丢帧，而是直播App退至后台导致音视频的采集被挂起。此时基本可以判定直播不畅的锅该由主播自己背，平台可以帮助矫正这个主播的使用姿势。

更进一步地，如果全部情况都表明主播的网络质量良好，操作正常，那么可以观察该直播流所连接节点的情况。若该节点其他的流也存在类似的波动，那么证明节点的负载过重，可为这些直播流进行推流节点的调度以优化推流质量。

以上，通过简单的几步查询，直播平台便能自助针对单个用户的问题进行定位排查，极大缩短了线上问题的解决周期，提升平台用户体验。

### 告警设置

除此之外，我们还为您创建的 Grafana 提供了完善多样的报警功能。使您能够对重点关注的直播质量指标进行监测，主动发现并解决问题。

我们同样以一个场景来说明告警的使用姿势。比如，您可能很关注播放终端的平均接收码率，因为它直接关系着用户观看的视觉体验。假设您期望播放码率的平均值应该在 800Kbps 以上，那么就可针对这个指标设置一个告警监控。如下图：
![图3.10 告警规则创建](http://owlznavag.bkt.clouddn.com/play-stats-alert-rule.png)

一旦监测的平均播放码率小于期望值，那么您将收到如下一个报警消息。此时，直播平台运维可快速做出响应，查看问题出现的原因。
![图3.11 告警消息](http://owlznavag.bkt.clouddn.com/play-stats-alert.png)

## 啊哈，原来如此!

那么，开通了基于 Pandora 大数据平台的直播质量监控之后，您的客户端质量数据又是如何被实时处理并呈现在您的面前呢？以下便为您揭晓个中奥秘。

### Logkit 过滤用户数据

直播 QoS 数据被客户端上报后会进入收点服务的消息队列(Kafka)中，利用 Pandora 的通用数据采集工具 [Logkit](https://qiniu.github.io/pandora-docs/#/util/logkit)，我们从消息队列中根据推流域名实时过滤并拉取不同客户的 QoS 数据，发送到对应客户账号的 Pandora 大数据工作流中。

事实上，Logkit 也适用于其他各种日志数据收集场景，比如：[10分钟内快速构建能够承载海量数据的 nginx 日志分析与报警平台](https://mp.weixin.qq.com/s/ccEHjzA0a0tYTVnHpuouPw)。更多的使用姿势，可参考[这些最佳实践](https://qiniu.github.io/pandora-docs/#/demo/nginxlog)。

### Pandora workflow 数据加工

在 Logkit 将您直播 QoS 数据上报至 Pandora 时，会自动建立如下一个大数据工作流，目前是将 QoS 数据直接导出至下游的 LogDB 日志检索服务。Pandora 还提供了其他多种导出选择，如导出到七牛对象存储，可将全量日志进行持久化；也可将日志转发到您自己的 HTTP 服务，使直播质量数据在您自己的服务框架中派上用场。
![图4.1 Pandora workflow 导出](http://owlznavag.bkt.clouddn.com/pandora-workflow-export.png)


### 分析维度延展

利用大数据工作流引擎，您可以利用上报到数据源中的 QoS 数据进行更多维度的自定义分析，只需在实时工作流中新建 Transform 计算任务，便能对上报的数据进行进一步的聚合处理，导出更多维度的数据。

例如，我们甚至可以利用 QoS 数据进行活跃用户数这类简单的运营统计分析，只需新建如下一个计算任务，加之简单的一段 SQL 代码，便能计算出各个省份每五分钟内安卓活跃用户的数量。计算结果可选择导出到 LogDB、时序数据库、七牛对象存储或是您本地架设的 HTTP 服务，即将Pandora的直播质量分析结果回流到您的平台进行落地。
![图4.2 Pandora workflow transform](http://owlznavag.bkt.clouddn.com/pandora-workflow-transform.png)

### 离线分析

除了利用实时工作流进行分析外，您还可创建离线的 XSpark，分析更多更久的海量数据，详见 [XSpark使用入门](https://qiniu.github.io/pandora-docs/#/quickstart/xspark)

## 后记

如果您已经是七牛直播云的用户，那么只需联系七牛 Pandora 团队申请开通，审核通过之后，我们将为您提供一个开箱即用的直播质量数据监控应用。

如果您使用的是非七牛的直播 SDK，那么，别着急，我们正在准备一个直播数据埋点 SDK，方便您进行相应的自定义直播质量数据上报。为了保障您的数据隐私安全，该 SDK 将全部开源，做到真正开放透明。同样地，欢迎联系我们，与我们交流您所期望的直播质量监控需求。


